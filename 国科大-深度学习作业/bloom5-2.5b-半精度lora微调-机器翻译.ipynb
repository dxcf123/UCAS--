{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5575fad4",
   "metadata": {},
   "source": [
    "# 源数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286db6b0",
   "metadata": {},
   "source": [
    "## 1 导入相关包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71e4ad43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin D:\\anac\\Lib\\site-packages\\bitsandbytes\\libbitsandbytes_cuda118.dll\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, DataCollatorForSeq2Seq, TrainingArguments, Trainer\n",
    "from peft import PeftModel\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "308115ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_path = r'H:\\datasets\\data\\翻译1\\test.en.txt'\n",
    "ch_path = r'H:\\datasets\\data\\翻译1\\test.ch.txt'\n",
    "csv_path=r'C:\\Users\\30535\\Desktop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ab20aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextToCsv:\n",
    "    ## 定义tokenizer,对原始数据进行处理\n",
    "    def __init__(self, en_path, ch_path,csv_path,text_pair_nums=50000):\n",
    "        \"\"\"\n",
    "        初始化\n",
    "        :param en_path: 英文数据路径\n",
    "        :param ch_path: 中文数据路径\n",
    "        :csv_path 文件保存路径\n",
    "        :text_pair_nums: 使用多少对数据\n",
    "        \"\"\"\n",
    "        self.en_path = en_path  # 英文路径\n",
    "        self.ch_path = ch_path  # 中文路径\n",
    "        self.text_pair_nums=text_pair_nums\n",
    "        \n",
    "        # 读取原始英文数据\n",
    "        self.en_data = self.__read_ori_data(en_path)\n",
    "        # 读取原始中文数据\n",
    "        self.ch_data = self.__read_ori_data(ch_path)\n",
    "        self.x=self.return_csv(csv_path)\n",
    "\n",
    "    def __read_ori_data(self, path):\n",
    "        \"\"\"\n",
    "        读取原始数据\n",
    "        :param path: 数据路径\n",
    "        :return: 返回一个列表，每个元素是一条数据\n",
    "        \"\"\"\n",
    "        with open(path, 'r', encoding='utf-8') as f:\n",
    "            data = f.read().split('\\n')[:-1]\n",
    "            self.text_pair_nums =self.text_pair_nums if self.text_pair_nums <=len(data) else len(data)\n",
    "            data = data[:self.text_pair_nums] \n",
    "        return data\n",
    "    \n",
    "    def return_csv(self,csv_path):\n",
    "        \"\"\"\n",
    "        将源数据处理成csv文件\n",
    "        :csv_path 文件保存路径\n",
    "        \"\"\"\n",
    "        data=[]\n",
    "        # 遍历所有数据，长度大于127的数据抛弃\n",
    "        for i in range(self.text_pair_nums):\n",
    "            if len(self.en_data[i])>127 or len(self.en_data[i])>127:\n",
    "                continue\n",
    "            # 英文→中文\n",
    "            data.append([\n",
    "                self.en_data[i],\n",
    "                self.ch_data[i]]\n",
    "            )\n",
    "            # 中文→英文\n",
    "            data.append([\n",
    "                self.ch_data[i],\n",
    "                self.en_data[i]]\n",
    "            )\n",
    "        random.shuffle(data) # 数据随机打乱\n",
    "        csv_train=os.path.join(csv_path,'train.csv') # 训练集文件\n",
    "        csv_test=os.path.join(csv_path,'test.csv') # 测试集文件\n",
    "        dat=pd.DataFrame(data[:len(data)-1000],columns=['src','tgt']) # 训练集\n",
    "        dat2=pd.DataFrame(data[len(data)-1000:],columns=['src','tgt']) # 测试集\n",
    "        dat.to_csv(csv_train,index=False) # 转换为csv文件\n",
    "        dat2.to_csv(csv_test,index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23e24831",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.TextToCsv at 0x13d8a27ab10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextToCsv(en_path,ch_path,csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfcfa66",
   "metadata": {},
   "source": [
    "## 1 导入相关包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dd34940",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, DataCollatorForSeq2Seq, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a540d7",
   "metadata": {},
   "source": [
    "## 2 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64d6fc0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Dataset({\n",
       "     features: ['src', 'tgt'],\n",
       "     num_rows: 92644\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['src', 'tgt'],\n",
       "     num_rows: 1000\n",
       " })]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train=r'C:\\Users\\30535\\Desktop\\train.csv'\n",
    "data_test=r'C:\\Users\\30535\\Desktop\\test.csv'\n",
    "ds=load_dataset('csv',data_files={'train':data_train, 'test': data_test},\n",
    "                                split=['train', 'test'])\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63ae622",
   "metadata": {},
   "source": [
    "## 4 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d71b691",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_path=r'H:\\models\\bloom-2b5-zh'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f48676e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_func(examples):\n",
    "    MAX_LENGTH = 150\n",
    "    contents='机器翻译:\\n' + examples['src']\n",
    "    # 对输入与label进行编码\n",
    "    inputs=tokenizer(contents)\n",
    "    labels = tokenizer(text_target=examples['tgt'] + tokenizer.eos_token)\n",
    "    input_ids=inputs[\"input_ids\"]+labels[\"input_ids\"]\n",
    "    attention_mask=inputs[\"attention_mask\"] + labels[\"attention_mask\"]\n",
    "    labels = [-100] * len(inputs[\"input_ids\"]) + labels[\"input_ids\"]\n",
    "    # 数据截断\n",
    "    if len(input_ids) > MAX_LENGTH:\n",
    "        input_ids = input_ids[:MAX_LENGTH]\n",
    "        attention_mask = attention_mask[:MAX_LENGTH]\n",
    "        labels = labels[:MAX_LENGTH]\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb8f1a88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ab01b873b7841eeac5440ce5443f642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/92644 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train=ds[0].map(process_func, remove_columns=ds[0].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a90825de",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 92644\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad20e4d9",
   "metadata": {},
   "source": [
    "## 5 创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f5fa333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c979eb86b81430198b6e1782f6d3d86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model=AutoModelForCausalLM.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fec97cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.half()\n",
    "model=model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320650bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3aaa4c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path=None, revision=None, task_type=<TaskType.CAUSAL_LM: 'CAUSAL_LM'>, inference_mode=False, r=8, target_modules=None, lora_alpha=8, lora_dropout=0.0, fan_in_fan_out=False, bias='none', modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6.1 创建配置文件\n",
    "from peft import LoraConfig,get_peft_model,TaskType\n",
    "comfig = LoraConfig(task_type=TaskType.CAUSAL_LM)\n",
    "comfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5cc4ec1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.2 创建模型\n",
    "model_lora = get_peft_model(model,comfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4495dfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lora=model_lora.half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1938044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译: 翻译\n"
     ]
    }
   ],
   "source": [
    "x=\"机器翻译:\\n{}\".format(\"what is this。\").strip()\n",
    "ipt = tokenizer(x,return_tensors='pt').to('cuda')\n",
    "print(tokenizer.decode(model.generate(**ipt,max_length=256, do_sample=False)[0],skip_special_tokens=True)[len(x):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33be677b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 2,457,600 || all params: 2,480,893,440 || trainable%: 0.09906108663820724\n"
     ]
    }
   ],
   "source": [
    "model_lora.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d689a5",
   "metadata": {},
   "source": [
    "## 7 配置训练参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77a2e300",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\" # 防止日志输出到wandb.ai\n",
    "args= TrainingArguments(\n",
    "                                  output_dir='./modelcheak/m3',\n",
    "                                  logging_dir=r'./modelcheak/m3',\n",
    "                                  per_device_train_batch_size=8,  # batch_size\n",
    "                                  gradient_accumulation_steps=4,\n",
    "                                  logging_steps=20,\n",
    "                                  optim=\"adafactor\",  # 使用特定的优化器优化显存\n",
    "                                  save_strategy='epoch',  # 每一轮保存一个模型\n",
    "                                  num_train_epochs=1,\n",
    "                                  adam_epsilon=1e-4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122adaa1",
   "metadata": {},
   "source": [
    "## 8 创建训练器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43b7e698",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainr=Trainer(\n",
    "    args=args,\n",
    "    model=model_lora,\n",
    "    train_dataset=tokenized_train,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0943fb9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2895' max='2895' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2895/2895 26:55, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.051300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.798100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.639400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.523500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.463700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2.394600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2.382400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>2.352300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>2.386000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.254800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>2.277300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>2.282400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>2.333800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>2.297500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.238400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>2.272300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>2.236500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>2.234700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>2.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.168200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>2.210200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>2.161000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>2.249600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>2.242700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.168200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>2.131500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>2.117000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>2.153500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>2.199800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.192000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>2.178200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>2.116700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>2.113900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>2.149100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.175600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>2.148900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>2.182600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>2.117200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>2.152000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.163600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>2.117500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>2.143200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>2.079800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>2.101300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.093500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>2.111800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>2.096700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>2.136000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>2.136700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.162500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>2.095500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>2.116100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1060</td>\n",
       "      <td>2.063400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>2.125400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>2.095900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120</td>\n",
       "      <td>2.088300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>2.076200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1160</td>\n",
       "      <td>2.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1180</td>\n",
       "      <td>2.105600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>2.086100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1220</td>\n",
       "      <td>2.060700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1240</td>\n",
       "      <td>2.068800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>2.031200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1280</td>\n",
       "      <td>2.091700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>2.137900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>2.107100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1340</td>\n",
       "      <td>2.075100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1360</td>\n",
       "      <td>2.118500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>2.069200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>2.089800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1420</td>\n",
       "      <td>2.062000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>2.085700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1460</td>\n",
       "      <td>2.076500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1480</td>\n",
       "      <td>2.075900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.106000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1520</td>\n",
       "      <td>2.060200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1540</td>\n",
       "      <td>2.085200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>2.098200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1580</td>\n",
       "      <td>2.076200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>2.116000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>2.058100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1640</td>\n",
       "      <td>2.114300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1660</td>\n",
       "      <td>2.079700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>2.032300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>2.082100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1720</td>\n",
       "      <td>2.073100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>2.069700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1760</td>\n",
       "      <td>2.087300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1780</td>\n",
       "      <td>2.036300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>2.067500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1820</td>\n",
       "      <td>2.122600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1840</td>\n",
       "      <td>2.090300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>2.044800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1880</td>\n",
       "      <td>2.181300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>2.036300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>2.008100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1940</td>\n",
       "      <td>2.083100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1960</td>\n",
       "      <td>2.022100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1980</td>\n",
       "      <td>2.089300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.084200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020</td>\n",
       "      <td>2.058900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2040</td>\n",
       "      <td>2.021600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2060</td>\n",
       "      <td>2.132200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2080</td>\n",
       "      <td>2.114400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>2.082700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2120</td>\n",
       "      <td>2.054100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2140</td>\n",
       "      <td>2.053700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2160</td>\n",
       "      <td>2.083600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2180</td>\n",
       "      <td>2.170300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>2.032100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2220</td>\n",
       "      <td>2.043000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2240</td>\n",
       "      <td>2.077600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2260</td>\n",
       "      <td>2.061400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2280</td>\n",
       "      <td>2.016500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>2.074100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2320</td>\n",
       "      <td>2.101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2340</td>\n",
       "      <td>2.072500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2360</td>\n",
       "      <td>1.994900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2380</td>\n",
       "      <td>1.989000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>2.077200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2420</td>\n",
       "      <td>2.039100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2440</td>\n",
       "      <td>2.113900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2460</td>\n",
       "      <td>2.129500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2480</td>\n",
       "      <td>2.087300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>2.096200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2520</td>\n",
       "      <td>2.025700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2540</td>\n",
       "      <td>2.103600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2560</td>\n",
       "      <td>2.031100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2580</td>\n",
       "      <td>1.992500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>2.047700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2620</td>\n",
       "      <td>2.028600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2640</td>\n",
       "      <td>2.057700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2660</td>\n",
       "      <td>2.072400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2680</td>\n",
       "      <td>2.011900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>2.067200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2720</td>\n",
       "      <td>2.052000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2740</td>\n",
       "      <td>2.070400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2760</td>\n",
       "      <td>2.095900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2780</td>\n",
       "      <td>2.038700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>2.063300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2820</td>\n",
       "      <td>2.083900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2840</td>\n",
       "      <td>2.022500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2860</td>\n",
       "      <td>1.947500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2880</td>\n",
       "      <td>1.995800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2895, training_loss=2.131528674506153, metrics={'train_runtime': 1615.9318, 'train_samples_per_second': 57.332, 'train_steps_per_second': 1.792, 'total_flos': 6.0358179078144e+16, 'train_loss': 2.131528674506153, 'epoch': 1.0})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainr.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae220ef",
   "metadata": {},
   "source": [
    "## 9 权重合并与"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5aca0d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "# model_id 是checkpoint那个路径\n",
    "prft_model=PeftModel.from_pretrained(model=model,model_id=r\"C:\\Users\\30535\\Desktop\\CodeProgram\\Python\\deepstudy\\code2\\使用Transformer进行中英文翻译\\modelcheak\\m3\\checkpoint-2895\")\n",
    "# 权重合并\n",
    "merge_model=prft_model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59fc687a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型保存\n",
    "merge_model.save_pretrained('./modelcheak/trans11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "876ab7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这是什么？\n"
     ]
    }
   ],
   "source": [
    "x=\"机器翻译:\\n{}\".format(\"what is this。\").strip()\n",
    "ipt = tokenizer(x,return_tensors='pt').to('cuda')\n",
    "print(tokenizer.decode(merge_model.generate(**ipt,max_length=256, do_sample=False)[0],skip_special_tokens=True)[len(x):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae2b6ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is this?\n"
     ]
    }
   ],
   "source": [
    "x=\"机器翻译:\\n{}\".format(\"这又是什么呢？\").strip()\n",
    "ipt = tokenizer(x,return_tensors='pt').to('cuda')\n",
    "print(tokenizer.decode(merge_model.generate(**ipt,max_length=256, do_sample=False)[0],skip_special_tokens=True)[len(x):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce272f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.04\n",
      "0.08\n",
      "时间 25.055421829223633\n",
      "17.161924767287793\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import sacrebleu\n",
    "def is_english_sentence(sentence):\n",
    "    # 使用正则表达式检查句子中是否包含英文字母\n",
    "    english_pattern = re.compile(r'[a-zA-Z]')\n",
    "    match = english_pattern.search(sentence)\n",
    "    \n",
    "    if match:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "\n",
    "smooth = SmoothingFunction().method1\n",
    "bleu_scores=[]\n",
    "m1,m2=[],[]\n",
    "m3,m4=[],[]\n",
    "import time\n",
    "t=time.time()\n",
    "for i in range(100):\n",
    "    if i%40==0:\n",
    "        print(i/len(ds[1]['src']))\n",
    "    x=\"机器翻译:\\n{}\".format(ds[1]['src'][i]).strip()\n",
    "    ipt = tokenizer(x,return_tensors='pt').to('cuda')\n",
    "    y=tokenizer.decode(merge_model.generate(**ipt,max_length=150, do_sample=False)[0],skip_special_tokens=True)[len(x):]\n",
    "    if is_english_sentence(ds[1]['tgt'][i]):\n",
    "        m1.append(ds[1]['tgt'][i])\n",
    "        m2.append([y])\n",
    "    else:\n",
    "        m3.append(list(ds[1]['tgt'][i][:-1]))\n",
    "        m4.append([list(y)[:-1]])\n",
    "print('时间',time.time()-t)\n",
    "smooth = SmoothingFunction().method1\n",
    "b1=[sacrebleu.sentence_bleu(candidate, refs).score for candidate, refs in zip(m1, m2)]\n",
    "for i in range(len(m4)):\n",
    "    b2 = sentence_bleu(m4[i], m3[i], weights=(0.25, 0.25, 0.25, 0.25), smoothing_function=smooth)*100\n",
    "    b1.append(b2)\n",
    "print(sum(b1)/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8162c152",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a092afd",
   "metadata": {},
   "source": [
    "## 9 模型推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "df9ad78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7145468b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model 'BloomForCausalLM' is not supported for text2text-generation. Supported models are ['BartForConditionalGeneration', 'BigBirdPegasusForConditionalGeneration', 'BlenderbotForConditionalGeneration', 'BlenderbotSmallForConditionalGeneration', 'EncoderDecoderModel', 'FSMTForConditionalGeneration', 'GPTSanJapaneseForConditionalGeneration', 'LEDForConditionalGeneration', 'LongT5ForConditionalGeneration', 'M2M100ForConditionalGeneration', 'MarianMTModel', 'MBartForConditionalGeneration', 'MT5ForConditionalGeneration', 'MvpForConditionalGeneration', 'NllbMoeForConditionalGeneration', 'PegasusForConditionalGeneration', 'PegasusXForConditionalGeneration', 'PLBartForConditionalGeneration', 'ProphetNetForConditionalGeneration', 'SwitchTransformersForConditionalGeneration', 'T5ForConditionalGeneration', 'UMT5ForConditionalGeneration', 'XLMProphetNetForConditionalGeneration'].\n"
     ]
    }
   ],
   "source": [
    "pipe=pipeline('text2text-generation',model=merge_model,tokenizer=tokenizer,device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "89d02ec1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '机器翻译:\\n我有一个苹果I have a Apple'}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe('机器翻译:\\n'+'我有一个苹果',max_length=30,do_sample=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
