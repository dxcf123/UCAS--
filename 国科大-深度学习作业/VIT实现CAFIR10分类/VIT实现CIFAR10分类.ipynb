{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "859542e6",
   "metadata": {},
   "source": [
    "## 1 导入相关包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a096699a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6baf97a8",
   "metadata": {},
   "source": [
    "## 2 获取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "207309e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(path, batch_size=32, transform=None):\n",
    "    \"\"\"\n",
    "    加载MNIST数据集并将其转换为DataLoader对象。\n",
    "    :param path: 数据集路径\n",
    "    :param batch_size: 批处理大小\n",
    "    :param transform: 数据预处理\n",
    "    :return: 训练集与测试集的DataLoader对象\n",
    "    \"\"\"\n",
    "    if transform is None:\n",
    "        transform = torchvision.transforms.Compose([  # 对图像进行预处理\n",
    "            torchvision.transforms.ToTensor(),  # 将图片转换成张量\n",
    "            torchvision.transforms.Normalize((0.5,), (0.5,))  # 对图像进行归一化处理\n",
    "        ])\n",
    "\n",
    "    train = CIFAR_Dataset(path, train=True, transform=transform)\n",
    "    tset = CIFAR_Dataset(path, train=False, transform=transform)\n",
    "\n",
    "    # 创建dataloader对象\n",
    "    train_loader = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(tset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11bcca7",
   "metadata": {},
   "source": [
    "## 3 数据集类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4928231",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR_Dataset(Dataset):\n",
    "    def __init__(self, data_dir, train, transform):  # 数据集的位置，训练集还是测试集，以及数据预处理的变换\n",
    "        super(CIFAR_Dataset, self).__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "        self.data = []\n",
    "        self.targets = []\n",
    "\n",
    "        # 判断是否为训练集\n",
    "        if self.train:\n",
    "            for i in range(5):  # CIFAR-10训练数据集有5个文件，所以要循环5次读取\n",
    "                with open(data_dir + '/cifar-10-batches-py/data_batch_' + str(i + 1), 'rb') as f:  # 二进制格式读取文件\n",
    "                    entry = pickle.load(f, encoding='latin1')  # 对文件进行反序列化成python对象\n",
    "                    self.data.append(entry['data'])  # 读取文件中data部分的数据并将其添加到self.data中\n",
    "                    self.targets.extend(entry['labels'])  # 读取文件中labels部分的数据并将其添加到self.targets中\n",
    "        else:  # 操作与上述相同，只是读取的是测试集\n",
    "            with open(data_dir + '/cifar-10-batches-py/test_batch', 'rb') as f:\n",
    "                entry = pickle.load(f, encoding='latin1')\n",
    "                self.data.append(entry['data'])\n",
    "                self.targets.extend(entry['labels'])\n",
    "        # 上面的操作是将数据添加到列表中，就会对整体数据添加一个纬度，\n",
    "        # 比如训练集本身是n*3*32*32,现在变成了 5*(n/5)*3*32*32,所以需要reshape一下,\n",
    "        # -1将5与n/5这两个纬度合并，变成n\n",
    "        self.data = np.vstack(self.data).reshape(-1, 3, 32, 32)\n",
    "        # 对纬度进行转置，这个跟图片数组相关\n",
    "        self.data = self.data.transpose((0, 2, 3, 1))\n",
    "\n",
    "    # 获取数据集长度\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    # 让对象能像数组一样根据下标访问\n",
    "    def __getitem__(self, idx):\n",
    "        # 这里是自己构建one-hot数组，可以利用torch.nn.functional 中的ont_hot函数进行变换\n",
    "        label = torch.zeros(10)\n",
    "        label[self.targets[idx]] = 1.\n",
    "\n",
    "        # 判断是否有预处理函数，如果有则对数据进行预处理\n",
    "        if self.transform:\n",
    "            image = self.transform(self.data[idx])\n",
    "        if self.train and idx > 0 and idx % 5 == 0:\n",
    "            # 获取一个数据集长度的随机数\n",
    "            mixup_idx = random.randint(0, len(self.data) - 1)\n",
    "            # 设置one_hot数组\n",
    "            mixup_label = torch.zeros(10)\n",
    "            label[self.targets[mixup_idx]] = 1.\n",
    "\n",
    "            # 如果存在预处理函数，则对数据集进行预处理\n",
    "            if self.transform:\n",
    "                mixup_image = self.transform(self.data[mixup_idx])\n",
    "\n",
    "            # 根据beta分布的随机数，对数据进行cutmix操作\n",
    "            mask = np.ones_like(image)  # 生成mask矩阵，用于对图像进行cut操作\n",
    "            la = float(np.random.beta(0.5, 0.5, 1))  # 生成一个符合beta分布的随机数\n",
    "            # 随机获取切割的部分\n",
    "            rx = np.int8(np.random.uniform(0, 32, 1))[0]\n",
    "            ry = np.int8(np.random.uniform(0, 32, 1))[0]\n",
    "            rw = np.int8(np.power(1 - la, 0.5) * 32)\n",
    "            rh = np.int8(np.power(1 - la, 0.5) * 32)\n",
    "            if rx > rw:\n",
    "                rx, rw = rw, rx\n",
    "            if ry > rh:\n",
    "                ry, rh = rh, ry\n",
    "            #  对图像进行cut操作\n",
    "            mask[rx:rw, ry:rh, :] = 0\n",
    "            #   对图像进行mix操作\n",
    "            image = image * mask + mixup_image * (1 - mask)\n",
    "            label = la * label + (1 - la) * mixup_label\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea772825",
   "metadata": {},
   "source": [
    "## 4 取patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39893c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image2embed(image, patch_size):\n",
    "    \"\"\"\n",
    "    将图像转换为嵌入向量\n",
    "    :param image: 图片  batch_size * channel * h * w\n",
    "    :param patch_size: 块大小\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    patch = F.unfold(image, kernel_size=patch_size, stride=patch_size).transpose(-1, -2)  # 将图片分成块，它实质是将卷积的部分直接取出来\n",
    "    return patch "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8b26bf",
   "metadata": {},
   "source": [
    "## 5 Embedding层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8695769",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    def __init__(self, channel, batchsize, psize, patchsize, emb_dim, device):\n",
    "        \"\"\"\n",
    "        词嵌入层\n",
    "        :param batchsize: 批量大小\n",
    "        :param psize: 用于位置编码的一个参数，它的大小等于  图片通道数 * (一张图片一行数据的大小//patchsize)²\n",
    "        :param patchsize: 提取图块的边长\n",
    "        :param emb_dim: 嵌入维度\n",
    "        :param device: 运算设备\n",
    "        \"\"\"\n",
    "        super(Embedding, self).__init__()\n",
    "        self.pathF = image2embed  # 导入提取图片块的函数\n",
    "        self.patchszie = patchsize  # 边长\n",
    "        self.emb_dim = emb_dim  # 嵌入纬度\n",
    "        self.l1 = nn.Linear(patchsize * patchsize * channel, emb_dim)  # 用于将图片块映射为为嵌入纬度大小\n",
    "        # 定义一个矩阵嵌入到输入数据开头，表示数据的开始\n",
    "        self.cls_token_emb = torch.randn(batchsize, 1, self.emb_dim, requires_grad=True, device=device)\n",
    "        # 位置编码\n",
    "        self.position_emb = torch.randn(1, psize, self.emb_dim, requires_grad=True, device=device)\n",
    "\n",
    "    def forward(self, x):  # 前向传播\n",
    "        \"\"\"\n",
    "        这里将图片块转换为嵌入纬度，加入了开头与位置编码\n",
    "        :param x:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        x = self.pathF(x, self.patchszie)\n",
    "        x = self.l1(x)\n",
    "        x = torch.cat((self.cls_token_emb[:x.shape[0]], x), dim=1)\n",
    "        x += self.position_emb\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86b94c6",
   "metadata": {},
   "source": [
    "## 6 注意力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94f0a575",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, emb_dim=128, head=8):\n",
    "        \"\"\"\n",
    "        注意力机制\n",
    "        :param emb_dim: 词嵌入纬度\n",
    "        :param head: 多头头数\n",
    "        \"\"\"\n",
    "        super(Attention, self).__init__()\n",
    "        assert emb_dim % head == 0  # 保证emb_dim可以整除head，注意力机制的词嵌入维度需要是多头的n倍\n",
    "        self.emb_dim = emb_dim  # 词嵌入纬度\n",
    "        self.head = head  # 多头\n",
    "        self.head_dim = emb_dim // head\n",
    "\n",
    "        # q k v 三个输入的线性层  维度变换 emb_dim → emb_dim\n",
    "        self.query_L = nn.Linear(emb_dim, emb_dim)\n",
    "        self.key_L = nn.Linear(emb_dim, emb_dim)\n",
    "        self.value_L = nn.Linear(emb_dim, emb_dim)\n",
    "\n",
    "    def forward(self, q, k, v):\n",
    "        \"\"\"\n",
    "        前向传播 q,k,v为transformer的三个输入，这里做了注意力机制的运算\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # q,k,v的形状为 batchsize 长度 词嵌入纬度 ，下面batchsize，长度，词嵌入纬度，头数，分别用 B L D H 代替\n",
    "        # 这里进行多头注意力机制进行计算，因此需要进行纬度变换\n",
    "        x_q = self.query_L(q)  # q 进行线性层变换 B,L,D → B,L,D\n",
    "        x_q = x_q.reshape(q.shape[0], q.shape[1], self.head, self.head_dim)  # B,L,D → B,L,H,D/H\n",
    "        x_q = x_q.transpose(1, 2)  # B,L,H,D/H → B,H,L,D/H\n",
    "        x_q = x_q.reshape(-1, q.shape[1], self.head_dim)  # B,H,L,D/H  → BH,L,D/H\n",
    "\n",
    "        # k,v操作与q相同\n",
    "        x_k = self.key_L(k).reshape(k.shape[0], k.shape[1], self.head, self.head_dim)\n",
    "        x_k = x_k.transpose(1, 2)\n",
    "        x_k = x_k.reshape(-1, k.shape[1], self.head_dim)\n",
    "\n",
    "        x_v = self.value_L(v).reshape(v.shape[0], v.shape[1], self.head, self.head_dim)\n",
    "        x_v = x_v.transpose(1, 2)\n",
    "        x_v = x_v.reshape(-1, v.shape[1], self.head_dim)\n",
    "\n",
    "        # 注意力机制计算，这里需要对x_K进行转置才符合运算规则\n",
    "        x_k = x_k.transpose(1, 2)  # BH,L,BH  →  BH,D/H,L\n",
    "        x_atten = torch.matmul(x_q, x_k) / (self.head_dim ** 0.5)  # q,k相乘并除以根号D → BH,L,L\n",
    "        x_atten = F.softmax(x_atten, dim=-1)\n",
    "\n",
    "        x_out = torch.matmul(x_atten, x_v)  # → BH,L,D/H\n",
    "        x_out = x_out.reshape(-1, self.head, x_out.shape[1], x_out.shape[2])  # BH,L,D/H → B,H,L,D/H\n",
    "        x_out = x_out.transpose(1, 2)  # B,H,L,D/H → B,L,H,D/H\n",
    "        x = x_out.reshape(-1, x_out.shape[1], self.head * self.head_dim)  # B,L,H,D/H->B,L,D\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b48bf3c",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## 7 Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f8f74a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, emb_dim=128, head=8):\n",
    "        \"\"\"\n",
    "        编码器\n",
    "        :param emb_dim: 嵌入维度\n",
    "        :param head: 多头头数\n",
    "        \"\"\"\n",
    "        super(Encoder, self).__init__()\n",
    "        self.Attention = Attention(emb_dim, head)  # 注意力机制\n",
    "        # 前馈全连接子层\n",
    "        self.l1 = nn.Linear(emb_dim, 1024)\n",
    "        self.l2 = nn.Linear(1024, emb_dim)\n",
    "        # 规范化层\n",
    "        self.norm1 = nn.LayerNorm(emb_dim)\n",
    "        self.norm2 = nn.LayerNorm(emb_dim)\n",
    "\n",
    "    def forward(self, q, k, v):  # 前向传播计算\n",
    "        # 注意力机制\n",
    "        x = self.Attention(q, k, v)\n",
    "        # 规范化层\n",
    "        x = self.norm1(x + q)\n",
    "        # 全连接层\n",
    "        x_ = self.l1(x)\n",
    "        x_ = F.gelu(x_)\n",
    "        x_ = self.l2(x_)\n",
    "        # 规范化层\n",
    "        x = self.norm2(x + x_)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31663c28",
   "metadata": {},
   "source": [
    "## 8 VIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36570bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VIT(nn.Module):\n",
    "    def __init__(self, channel, batchsize, psize, patchsize, emb_dim, head, device, N=3):\n",
    "        \"\"\"\n",
    "        VIT模型\n",
    "        :param batchsize: 批量\n",
    "        :param psize: 用于位置编码的一个参数，它的大小等于  图片通道数 * (一张图片一行数据的大小//patchsize)²\n",
    "        :param patchsize: 图片块边长\n",
    "        :param emb_dim: 嵌入维度\n",
    "        :param head: 多头\n",
    "        :param device: 运算设备\n",
    "        \"\"\"\n",
    "        super(VIT, self).__init__()\n",
    "        self.Embed = Embedding(channel, batchsize, psize, patchsize, emb_dim, device)  # 词嵌入层\n",
    "        self.Encoder = torch.nn.ModuleList([Encoder(emb_dim, head) for _ in range(N)])\n",
    "        # 用于分类的全连接层\n",
    "        self.l1 = nn.Linear(emb_dim, 1024)\n",
    "        self.l2 = nn.Linear(1024, 10)  # CIFAR10 10分类\n",
    "\n",
    "    def forward(self, x):\n",
    "        #  词嵌入层\n",
    "        x = self.Embed(x)\n",
    "        #  编码器层\n",
    "        for i in self.Encoder:\n",
    "            x = i(x, x, x)\n",
    "        #  分类层\n",
    "        x = self.l1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.l2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73216d6a",
   "metadata": {},
   "source": [
    "## 9 准确率函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "491b4b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testacc(model, test, epoch, device):\n",
    "    \"\"\"\n",
    "    测试准确率\n",
    "    :param model: 模型\n",
    "    :param test: 测试集\n",
    "    :param epoch: 第epoch轮\n",
    "    :param device: 设备\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    all = 0  # 样本总数\n",
    "    right = 0  # 正确个数\n",
    "    model.eval()\n",
    "    for i, (data, label) in enumerate(test):\n",
    "        all += 128\n",
    "        data = data.to(device)\n",
    "        label = label.to(device)\n",
    "        pre = model(data)[:, 0, :]\n",
    "        pre = torch.argmax(pre, dim=-1)  # 获取最大值标签\n",
    "        label=torch.argmax(label, dim=-1)\n",
    "        right += (pre == label).sum()  # 统计每轮正确的数量\n",
    "    print(epoch, right / all)\n",
    "    return right / all\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00de2ce",
   "metadata": {},
   "source": [
    "## 10 训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "751e52f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(path, batchsize, patchsize, emb_dim=256, head=8, device='cpu', lr=3e-4, N=6):\n",
    "    \"\"\"\n",
    "    训练模型\n",
    "    :param path: 数据集路径\n",
    "    :param batchsize: 批量大小\n",
    "    :param patchsize: 块大小\n",
    "    :param emb_dim: 嵌入纬度\n",
    "    :param head: 多头\n",
    "    :param device: 设备\n",
    "    :param lr: 学习率\n",
    "    :param N: Encoder层数\n",
    "    :return: 模型\n",
    "    \"\"\"\n",
    "    train, test = get_dataset(path, batchsize)\n",
    "    # 损失函数\n",
    "    lossf = nn.CrossEntropyLoss()\n",
    "\n",
    "    # 用于位置编码的一个参数，它的大小等于  图片通道数 * (一张图片一行数据的大小//patchsize)²\n",
    "    psize = (32 // patchsize) * (32 // patchsize) + 1\n",
    "    channel = 3  # 图片通道数\n",
    "\n",
    "    # 创建VIT模型\n",
    "    model = VIT(channel, batchsize, psize, patchsize, emb_dim, head, device, N=N)\n",
    "    # 设置优化器\n",
    "    optm = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    model = model.to(device)\n",
    "    loss_all=[]\n",
    "    acc_=[]\n",
    "    for epo in range(30):\n",
    "        model.train()\n",
    "        for i, (data, label) in enumerate(train):\n",
    "            data = data.to(device)\n",
    "            label = label.to(device)\n",
    "            optm.zero_grad()\n",
    "            pre = model(data)[:, 0, :]\n",
    "            loss = lossf(pre, label.float())\n",
    "            loss.backward()\n",
    "            optm.step()\n",
    "            if i%60==0:\n",
    "                loss_all.append(float(loss))\n",
    "                print(epo,i)\n",
    "                acc_.append(testacc(model, test, epo, device)) \n",
    "    with open('loss.txt','w',encoding=\"utf-8\") as f:\n",
    "        f.write(str(loss_all))\n",
    "    with open('acc.txt','w',encoding=\"utf-8\") as f:\n",
    "        f.write(str(acc_))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f5b832d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "0 tensor(0.0992, device='cuda:0')\n",
      "0 60\n",
      "0 tensor(0.2447, device='cuda:0')\n",
      "0 120\n",
      "0 tensor(0.3160, device='cuda:0')\n",
      "0 180\n",
      "0 tensor(0.3461, device='cuda:0')\n",
      "0 240\n",
      "0 tensor(0.3861, device='cuda:0')\n",
      "0 300\n",
      "0 tensor(0.4229, device='cuda:0')\n",
      "0 360\n",
      "0 tensor(0.4019, device='cuda:0')\n",
      "1 0\n",
      "1 tensor(0.4522, device='cuda:0')\n",
      "1 60\n",
      "1 tensor(0.4715, device='cuda:0')\n",
      "1 120\n",
      "1 tensor(0.4833, device='cuda:0')\n",
      "1 180\n",
      "1 tensor(0.4949, device='cuda:0')\n",
      "1 240\n",
      "1 tensor(0.4910, device='cuda:0')\n",
      "1 300\n",
      "1 tensor(0.4928, device='cuda:0')\n",
      "1 360\n",
      "1 tensor(0.5100, device='cuda:0')\n",
      "2 0\n",
      "2 tensor(0.5118, device='cuda:0')\n",
      "2 60\n",
      "2 tensor(0.5145, device='cuda:0')\n",
      "2 120\n",
      "2 tensor(0.5345, device='cuda:0')\n",
      "2 180\n",
      "2 tensor(0.5357, device='cuda:0')\n",
      "2 240\n",
      "2 tensor(0.5302, device='cuda:0')\n",
      "2 300\n",
      "2 tensor(0.5432, device='cuda:0')\n",
      "2 360\n",
      "2 tensor(0.5402, device='cuda:0')\n",
      "3 0\n",
      "3 tensor(0.5415, device='cuda:0')\n",
      "3 60\n",
      "3 tensor(0.5611, device='cuda:0')\n",
      "3 120\n",
      "3 tensor(0.5490, device='cuda:0')\n",
      "3 180\n",
      "3 tensor(0.5628, device='cuda:0')\n",
      "3 240\n",
      "3 tensor(0.5557, device='cuda:0')\n",
      "3 300\n",
      "3 tensor(0.5547, device='cuda:0')\n",
      "3 360\n",
      "3 tensor(0.5759, device='cuda:0')\n",
      "4 0\n",
      "4 tensor(0.5691, device='cuda:0')\n",
      "4 60\n",
      "4 tensor(0.5798, device='cuda:0')\n",
      "4 120\n",
      "4 tensor(0.5832, device='cuda:0')\n",
      "4 180\n",
      "4 tensor(0.5688, device='cuda:0')\n",
      "4 240\n",
      "4 tensor(0.5766, device='cuda:0')\n",
      "4 300\n",
      "4 tensor(0.5724, device='cuda:0')\n",
      "4 360\n",
      "4 tensor(0.5961, device='cuda:0')\n",
      "5 0\n",
      "5 tensor(0.5797, device='cuda:0')\n",
      "5 60\n",
      "5 tensor(0.5829, device='cuda:0')\n",
      "5 120\n",
      "5 tensor(0.5791, device='cuda:0')\n",
      "5 180\n",
      "5 tensor(0.5969, device='cuda:0')\n",
      "5 240\n",
      "5 tensor(0.5923, device='cuda:0')\n",
      "5 300\n",
      "5 tensor(0.6007, device='cuda:0')\n",
      "5 360\n",
      "5 tensor(0.6037, device='cuda:0')\n",
      "6 0\n",
      "6 tensor(0.6040, device='cuda:0')\n",
      "6 60\n",
      "6 tensor(0.5924, device='cuda:0')\n",
      "6 120\n",
      "6 tensor(0.6029, device='cuda:0')\n",
      "6 180\n",
      "6 tensor(0.5989, device='cuda:0')\n",
      "6 240\n",
      "6 tensor(0.6012, device='cuda:0')\n",
      "6 300\n",
      "6 tensor(0.6108, device='cuda:0')\n",
      "6 360\n",
      "6 tensor(0.6027, device='cuda:0')\n",
      "7 0\n",
      "7 tensor(0.5947, device='cuda:0')\n",
      "7 60\n",
      "7 tensor(0.5955, device='cuda:0')\n",
      "7 120\n",
      "7 tensor(0.6001, device='cuda:0')\n",
      "7 180\n",
      "7 tensor(0.6050, device='cuda:0')\n",
      "7 240\n",
      "7 tensor(0.6012, device='cuda:0')\n",
      "7 300\n",
      "7 tensor(0.6103, device='cuda:0')\n",
      "7 360\n",
      "7 tensor(0.6031, device='cuda:0')\n",
      "8 0\n",
      "8 tensor(0.6123, device='cuda:0')\n",
      "8 60\n",
      "8 tensor(0.6185, device='cuda:0')\n",
      "8 120\n",
      "8 tensor(0.6096, device='cuda:0')\n",
      "8 180\n",
      "8 tensor(0.6048, device='cuda:0')\n",
      "8 240\n",
      "8 tensor(0.6045, device='cuda:0')\n",
      "8 300\n",
      "8 tensor(0.6104, device='cuda:0')\n",
      "8 360\n",
      "8 tensor(0.6049, device='cuda:0')\n",
      "9 0\n",
      "9 tensor(0.6090, device='cuda:0')\n",
      "9 60\n",
      "9 tensor(0.6111, device='cuda:0')\n",
      "9 120\n",
      "9 tensor(0.6083, device='cuda:0')\n",
      "9 180\n",
      "9 tensor(0.6088, device='cuda:0')\n",
      "9 240\n",
      "9 tensor(0.5980, device='cuda:0')\n",
      "9 300\n",
      "9 tensor(0.6141, device='cuda:0')\n",
      "9 360\n",
      "9 tensor(0.6097, device='cuda:0')\n",
      "10 0\n",
      "10 tensor(0.6094, device='cuda:0')\n",
      "10 60\n",
      "10 tensor(0.6084, device='cuda:0')\n",
      "10 120\n",
      "10 tensor(0.6103, device='cuda:0')\n",
      "10 180\n",
      "10 tensor(0.6061, device='cuda:0')\n",
      "10 240\n",
      "10 tensor(0.6044, device='cuda:0')\n",
      "10 300\n",
      "10 tensor(0.6112, device='cuda:0')\n",
      "10 360\n",
      "10 tensor(0.6021, device='cuda:0')\n",
      "11 0\n",
      "11 tensor(0.6023, device='cuda:0')\n",
      "11 60\n",
      "11 tensor(0.6071, device='cuda:0')\n",
      "11 120\n",
      "11 tensor(0.6035, device='cuda:0')\n",
      "11 180\n",
      "11 tensor(0.6023, device='cuda:0')\n",
      "11 240\n",
      "11 tensor(0.6124, device='cuda:0')\n",
      "11 300\n",
      "11 tensor(0.6047, device='cuda:0')\n",
      "11 360\n",
      "11 tensor(0.6027, device='cuda:0')\n",
      "12 0\n",
      "12 tensor(0.6105, device='cuda:0')\n",
      "12 60\n",
      "12 tensor(0.6082, device='cuda:0')\n",
      "12 120\n",
      "12 tensor(0.6017, device='cuda:0')\n",
      "12 180\n",
      "12 tensor(0.6121, device='cuda:0')\n",
      "12 240\n",
      "12 tensor(0.6046, device='cuda:0')\n",
      "12 300\n",
      "12 tensor(0.5969, device='cuda:0')\n",
      "12 360\n",
      "12 tensor(0.6027, device='cuda:0')\n",
      "13 0\n",
      "13 tensor(0.6089, device='cuda:0')\n",
      "13 60\n",
      "13 tensor(0.5977, device='cuda:0')\n",
      "13 120\n",
      "13 tensor(0.6056, device='cuda:0')\n",
      "13 180\n",
      "13 tensor(0.6127, device='cuda:0')\n",
      "13 240\n",
      "13 tensor(0.6042, device='cuda:0')\n",
      "13 300\n",
      "13 tensor(0.6103, device='cuda:0')\n",
      "13 360\n",
      "13 tensor(0.6022, device='cuda:0')\n",
      "14 0\n",
      "14 tensor(0.5984, device='cuda:0')\n",
      "14 60\n",
      "14 tensor(0.6025, device='cuda:0')\n",
      "14 120\n",
      "14 tensor(0.6047, device='cuda:0')\n",
      "14 180\n",
      "14 tensor(0.6091, device='cuda:0')\n",
      "14 240\n",
      "14 tensor(0.6050, device='cuda:0')\n",
      "14 300\n",
      "14 tensor(0.6036, device='cuda:0')\n",
      "14 360\n",
      "14 tensor(0.6066, device='cuda:0')\n",
      "15 0\n",
      "15 tensor(0.6083, device='cuda:0')\n",
      "15 60\n",
      "15 tensor(0.6118, device='cuda:0')\n",
      "15 120\n",
      "15 tensor(0.6060, device='cuda:0')\n",
      "15 180\n",
      "15 tensor(0.6021, device='cuda:0')\n",
      "15 240\n",
      "15 tensor(0.6104, device='cuda:0')\n",
      "15 300\n",
      "15 tensor(0.6018, device='cuda:0')\n",
      "15 360\n",
      "15 tensor(0.6090, device='cuda:0')\n",
      "16 0\n",
      "16 tensor(0.6035, device='cuda:0')\n",
      "16 60\n",
      "16 tensor(0.6037, device='cuda:0')\n",
      "16 120\n",
      "16 tensor(0.6063, device='cuda:0')\n",
      "16 180\n",
      "16 tensor(0.6121, device='cuda:0')\n",
      "16 240\n",
      "16 tensor(0.6162, device='cuda:0')\n",
      "16 300\n",
      "16 tensor(0.6128, device='cuda:0')\n",
      "16 360\n",
      "16 tensor(0.6038, device='cuda:0')\n",
      "17 0\n",
      "17 tensor(0.6063, device='cuda:0')\n",
      "17 60\n",
      "17 tensor(0.6162, device='cuda:0')\n",
      "17 120\n",
      "17 tensor(0.6064, device='cuda:0')\n",
      "17 180\n",
      "17 tensor(0.6113, device='cuda:0')\n",
      "17 240\n",
      "17 tensor(0.6127, device='cuda:0')\n",
      "17 300\n",
      "17 tensor(0.6057, device='cuda:0')\n",
      "17 360\n",
      "17 tensor(0.6076, device='cuda:0')\n",
      "18 0\n",
      "18 tensor(0.6043, device='cuda:0')\n",
      "18 60\n",
      "18 tensor(0.6090, device='cuda:0')\n",
      "18 120\n",
      "18 tensor(0.6089, device='cuda:0')\n",
      "18 180\n",
      "18 tensor(0.6103, device='cuda:0')\n",
      "18 240\n",
      "18 tensor(0.6115, device='cuda:0')\n",
      "18 300\n",
      "18 tensor(0.6146, device='cuda:0')\n",
      "18 360\n",
      "18 tensor(0.6073, device='cuda:0')\n",
      "19 0\n",
      "19 tensor(0.6082, device='cuda:0')\n",
      "19 60\n",
      "19 tensor(0.6091, device='cuda:0')\n",
      "19 120\n",
      "19 tensor(0.6079, device='cuda:0')\n",
      "19 180\n",
      "19 tensor(0.6099, device='cuda:0')\n",
      "19 240\n",
      "19 tensor(0.6097, device='cuda:0')\n",
      "19 300\n",
      "19 tensor(0.6128, device='cuda:0')\n",
      "19 360\n",
      "19 tensor(0.6111, device='cuda:0')\n",
      "20 0\n",
      "20 tensor(0.6036, device='cuda:0')\n",
      "20 60\n",
      "20 tensor(0.5996, device='cuda:0')\n",
      "20 120\n",
      "20 tensor(0.6029, device='cuda:0')\n",
      "20 180\n",
      "20 tensor(0.6095, device='cuda:0')\n",
      "20 240\n",
      "20 tensor(0.6073, device='cuda:0')\n",
      "20 300\n",
      "20 tensor(0.6169, device='cuda:0')\n",
      "20 360\n",
      "20 tensor(0.6113, device='cuda:0')\n",
      "21 0\n",
      "21 tensor(0.6059, device='cuda:0')\n",
      "21 60\n",
      "21 tensor(0.6070, device='cuda:0')\n",
      "21 120\n",
      "21 tensor(0.6050, device='cuda:0')\n",
      "21 180\n",
      "21 tensor(0.6044, device='cuda:0')\n",
      "21 240\n",
      "21 tensor(0.5958, device='cuda:0')\n",
      "21 300\n",
      "21 tensor(0.6039, device='cuda:0')\n",
      "21 360\n",
      "21 tensor(0.6050, device='cuda:0')\n",
      "22 0\n",
      "22 tensor(0.6053, device='cuda:0')\n",
      "22 60\n",
      "22 tensor(0.6127, device='cuda:0')\n",
      "22 120\n",
      "22 tensor(0.6110, device='cuda:0')\n",
      "22 180\n",
      "22 tensor(0.6072, device='cuda:0')\n",
      "22 240\n",
      "22 tensor(0.5959, device='cuda:0')\n",
      "22 300\n",
      "22 tensor(0.6077, device='cuda:0')\n",
      "22 360\n",
      "22 tensor(0.6007, device='cuda:0')\n",
      "23 0\n",
      "23 tensor(0.6027, device='cuda:0')\n",
      "23 60\n",
      "23 tensor(0.6108, device='cuda:0')\n",
      "23 120\n",
      "23 tensor(0.6128, device='cuda:0')\n",
      "23 180\n",
      "23 tensor(0.6108, device='cuda:0')\n",
      "23 240\n",
      "23 tensor(0.6111, device='cuda:0')\n",
      "23 300\n",
      "23 tensor(0.6141, device='cuda:0')\n",
      "23 360\n",
      "23 tensor(0.6113, device='cuda:0')\n",
      "24 0\n",
      "24 tensor(0.6064, device='cuda:0')\n",
      "24 60\n",
      "24 tensor(0.6132, device='cuda:0')\n",
      "24 120\n",
      "24 tensor(0.6133, device='cuda:0')\n",
      "24 180\n",
      "24 tensor(0.6085, device='cuda:0')\n",
      "24 240\n",
      "24 tensor(0.6097, device='cuda:0')\n",
      "24 300\n",
      "24 tensor(0.6058, device='cuda:0')\n",
      "24 360\n",
      "24 tensor(0.6135, device='cuda:0')\n",
      "25 0\n",
      "25 tensor(0.6071, device='cuda:0')\n",
      "25 60\n",
      "25 tensor(0.6111, device='cuda:0')\n",
      "25 120\n",
      "25 tensor(0.6070, device='cuda:0')\n",
      "25 180\n",
      "25 tensor(0.6056, device='cuda:0')\n",
      "25 240\n",
      "25 tensor(0.6079, device='cuda:0')\n",
      "25 300\n",
      "25 tensor(0.6062, device='cuda:0')\n",
      "25 360\n",
      "25 tensor(0.6010, device='cuda:0')\n",
      "26 0\n",
      "26 tensor(0.6086, device='cuda:0')\n",
      "26 60\n",
      "26 tensor(0.6085, device='cuda:0')\n",
      "26 120\n",
      "26 tensor(0.6113, device='cuda:0')\n",
      "26 180\n",
      "26 tensor(0.6059, device='cuda:0')\n",
      "26 240\n",
      "26 tensor(0.6096, device='cuda:0')\n",
      "26 300\n",
      "26 tensor(0.6199, device='cuda:0')\n",
      "26 360\n",
      "26 tensor(0.6057, device='cuda:0')\n",
      "27 0\n",
      "27 tensor(0.6109, device='cuda:0')\n",
      "27 60\n",
      "27 tensor(0.6054, device='cuda:0')\n",
      "27 120\n",
      "27 tensor(0.6108, device='cuda:0')\n",
      "27 180\n",
      "27 tensor(0.6093, device='cuda:0')\n",
      "27 240\n",
      "27 tensor(0.6022, device='cuda:0')\n",
      "27 300\n",
      "27 tensor(0.5998, device='cuda:0')\n",
      "27 360\n",
      "27 tensor(0.6022, device='cuda:0')\n",
      "28 0\n",
      "28 tensor(0.6054, device='cuda:0')\n",
      "28 60\n",
      "28 tensor(0.6113, device='cuda:0')\n",
      "28 120\n",
      "28 tensor(0.6080, device='cuda:0')\n",
      "28 180\n",
      "28 tensor(0.6099, device='cuda:0')\n",
      "28 240\n",
      "28 tensor(0.5978, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 300\n",
      "28 tensor(0.6014, device='cuda:0')\n",
      "28 360\n",
      "28 tensor(0.6080, device='cuda:0')\n",
      "29 0\n",
      "29 tensor(0.6072, device='cuda:0')\n",
      "29 60\n",
      "29 tensor(0.6119, device='cuda:0')\n",
      "29 120\n",
      "29 tensor(0.6162, device='cuda:0')\n",
      "29 180\n",
      "29 tensor(0.6046, device='cuda:0')\n",
      "29 240\n",
      "29 tensor(0.6069, device='cuda:0')\n",
      "29 300\n",
      "29 tensor(0.6171, device='cuda:0')\n",
      "29 360\n",
      "29 tensor(0.6123, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "batchsize = 128\n",
    "patchsize = 4\n",
    "path = r'C:\\Users\\30535\\Desktop\\CodeProgram\\Python\\deepstudy\\data'\n",
    "\n",
    "model = train(path, batchsize, patchsize, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e34347e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "import matplotlib.pyplot as plt\n",
    "import re \n",
    "with open('loss.txt','r',encoding=\"utf-8\") as f:\n",
    "    data=eval(f.read())\n",
    "# d=[]\n",
    "# s='\\d.\\d+'\n",
    "# for i in data:\n",
    "#     aa=re.findall(s,i)[0]\n",
    "#     d.append(float(aa))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot([i*60 for i in range(len(data))],data)\n",
    "plt.xlabel('batch_num')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
