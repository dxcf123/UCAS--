{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66d04f04",
   "metadata": {},
   "source": [
    "## 1. 导入相关包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd76a5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载和预处理数据集\n",
    "import torch\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a6e6e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trans_train = transforms.Compose(\n",
    "    [transforms.RandomCrop(32,padding=6),  # 将给定图像随机裁剪为不同的大小和宽高比，#然后缩放所裁剪得到的图像为制定的大小;\n",
    "     # （即先随机采集,然后对裁剪得到的图像缩放为同一大小）默认scale=(0.08,1.0)\n",
    "     transforms.RandomHorizontalFlip(),  # 以给定的概率随机水平旋转给定的PIL的图像，默认为0.5;\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                          std=[0.229, 0.224, 0.225])])\n",
    "trans_valid = transforms.Compose(\n",
    "    [   #transforms.Resize(64),  # 是按照比例把图像最小的一个边长放缩到256，另一边按照相同比例放缩。\n",
    "        #transforms.CenterCrop(28),#依据给定的size从中心裁剪\n",
    "        transforms.ToTensor(),\n",
    "        # 将PIL Image或者ndarray 转换为tensor，并且归一化至[0-1]#归一化至[0-1]是直接除以255，若自己的ndarray数据尺度有变化，则需要自行修改。\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "# 对数据按通道进行标准化，即先减均值，再除以标准差，注意是 hwc\n",
    "trainset = torchvision.datasets.CIFAR10(root=r\"H:\\datasets\\data\", train=True, download=True, transform=trans_train)\n",
    "trainloader = DataLoader(trainset, batch_size=256, shuffle=True)\n",
    "testset = torchvision.datasets.CIFAR10(root=r'H:\\datasets\\data', train=False,\n",
    "                                       download=False, transform=trans_valid)\n",
    "testloader = DataLoader(testset, batch_size=256, shuffle=False)\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse ', 'ship', 'truck ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e23ad4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0228444",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim=128, heads=8, dim_head=64, dropout=0.):\n",
    "        super(Attention, self).__init__()\n",
    "        inner_dim = dim_head * heads\n",
    "        project_out = not (heads == 1 and dim_head == dim)\n",
    "        self.heads = heads\n",
    "        self.scale = dim_head ** -0.5\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.attend = nn.Softmax(dim=-1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias=False)\n",
    "        self.to_out = nn.Sequential(\n",
    "            nn.Linear(inner_dim, dim), nn.Dropout(dropout)\n",
    "        ) if project_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm(x)\n",
    "        qkv = self.to_qkv(x).chunk(3, dim=-1)\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d)->b h n d', h=self.heads), qkv)\n",
    "        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n",
    "        attn = self.attend(dots)\n",
    "        attn = self.dropout(attn)\n",
    "        out = torch.matmul(attn, v)\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
    "        return self.to_out(out)\n",
    "\n",
    "\n",
    "class ViT(nn.Module):\n",
    "    def __init__(self, num_classes=10, dim=512, depth=6, heads=8, mlp_dim=512, pool='cls', channels=3, dim_head=64,\n",
    "                 dropout=0.1, emb_dropout=0.1):\n",
    "        super().__init__()\n",
    "        image_height = 32\n",
    "        patch_height = 4\n",
    "        image_width = 32\n",
    "        patch_width = 4\n",
    "        num_patches = (image_height // patch_height) * (image_width // patch_width)\n",
    "        patch_dim = channels * patch_height * patch_width\n",
    "        self.to_patch_embedding = nn.Sequential(\n",
    "            Rearrange('b c (h p1) (w p2)->b (h w) (p1 p2 c) ', p1=patch_height, p2=patch_width),\n",
    "            nn.LayerNorm(patch_dim),\n",
    "            nn.Linear(patch_dim, dim), nn.LayerNorm(dim), )\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n",
    "        self.cls_token = nn.Parameter(\n",
    "            torch.randn(1, 1, dim))\n",
    "        self.dropout = nn.Dropout(emb_dropout)\n",
    "        self.transformer = Encoder(dim, depth, heads, dim_head, mlp_dim, dropout)\n",
    "        self.pool = pool\n",
    "        self.to_latent = nn.Identity()\n",
    "        self.mlp_head = nn.Linear(dim, num_classes)\n",
    "\n",
    "    def forward(self, img):\n",
    "        x = self.to_patch_embedding(img)\n",
    "        b, n, _ = x.shape\n",
    "\n",
    "        cls_tokens = repeat(self.cls_token, '1 1 d -> b 1 d', b=b)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "        x += self.pos_embedding[:, :(n + 1)]\n",
    "        x = self.dropout(x)\n",
    "        x = self.transformer(x)\n",
    "        x = x.mean(dim=1) if self.pool == 'mean' else x[:, 0]\n",
    "        x = self.to_latent(x)\n",
    "        return self.mlp_head(x)\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, dim=512, depth=6, heads=8, dim_head=64, mlp_dim=512, dropout=0.):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.layers = nn.ModuleList([])\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                Attention(dim=dim, heads=heads, dim_head=dim_head, dropout=dropout),\n",
    "                FeedForward(dim, mlp_dim, dropout=dropout)\n",
    "            ]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for attn, ff in self.layers:\n",
    "            x = attn(x) + x\n",
    "            x = ff(x) + x\n",
    "        return self.norm(x)\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, dropout=0.):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.Linear(dim, hidden_dim), nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, dim), nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a32b1faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    print(' \\nEpoch: %d' % epoch)\n",
    "    model = ViT()\n",
    "    device = 'cuda'\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "    net = model.to(device)\n",
    "    net.to(device)\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    t = time.time()\n",
    "    loss_all=[]\n",
    "    acc_=[]\n",
    "    for e in range(epoch):\n",
    "        net.train()\n",
    "        \n",
    "        for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            # sparse_selection()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "        loss_all.append(float(loss))\n",
    "        acc1=te(net, device, criterion)\n",
    "        acc_.append(float(acc1))\n",
    "        print(e, acc1)\n",
    "        print(time.time() - t)\n",
    "    with open('loss.txt','w',encoding=\"utf-8\") as f:\n",
    "        f.write(str(loss_all))\n",
    "    with open('acc.txt','w',encoding=\"utf-8\") as f:\n",
    "        f.write(str(acc_))\n",
    "    torch.save(model.state_dict(),'./model1.pt')\n",
    "\n",
    "\n",
    "def te(net, device, criterion):\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss += loss.item()\n",
    "            _,predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "462f2e28",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Epoch: 350\n",
      "0 0.4804\n",
      "28.50688886642456\n",
      "1 0.5269\n",
      "56.97822833061218\n",
      "2 0.57\n",
      "85.51609563827515\n",
      "3 0.5782\n",
      "114.19909739494324\n",
      "4 0.6055\n",
      "142.78727746009827\n",
      "5 0.6081\n",
      "171.57024955749512\n",
      "6 0.6385\n",
      "200.20650720596313\n",
      "7 0.6483\n",
      "228.89482879638672\n",
      "8 0.6462\n",
      "257.56299448013306\n",
      "9 0.6743\n",
      "286.2913861274719\n",
      "10 0.6811\n",
      "315.4403626918793\n",
      "11 0.6927\n",
      "344.35603857040405\n",
      "12 0.6761\n",
      "373.19810366630554\n",
      "13 0.6996\n",
      "401.95400047302246\n",
      "14 0.7202\n",
      "430.8852138519287\n",
      "15 0.7189\n",
      "459.7382140159607\n",
      "16 0.7213\n",
      "488.5429470539093\n",
      "17 0.7251\n",
      "517.4018700122833\n",
      "18 0.7371\n",
      "546.2356767654419\n",
      "19 0.7413\n",
      "575.1401631832123\n",
      "20 0.7443\n",
      "603.9621634483337\n",
      "21 0.7579\n",
      "632.8306040763855\n",
      "22 0.7506\n",
      "661.5786106586456\n",
      "23 0.7589\n",
      "690.3726100921631\n",
      "24 0.7659\n",
      "719.287611246109\n",
      "25 0.7619\n",
      "748.0530767440796\n",
      "26 0.7697\n",
      "776.8490719795227\n",
      "27 0.767\n",
      "805.6145973205566\n",
      "28 0.7795\n",
      "834.4780602455139\n",
      "29 0.7853\n",
      "863.4260601997375\n",
      "30 0.7853\n",
      "892.457897901535\n",
      "31 0.781\n",
      "921.4418935775757\n",
      "32 0.7843\n",
      "950.5259001255035\n",
      "33 0.7963\n",
      "979.3449013233185\n",
      "34 0.7954\n",
      "1008.3544545173645\n",
      "35 0.8087\n",
      "1037.9434542655945\n",
      "36 0.8096\n",
      "1066.7548418045044\n",
      "37 0.8065\n",
      "1096.0175104141235\n",
      "38 0.8064\n",
      "1124.8175089359283\n",
      "39 0.8135\n",
      "1153.6377708911896\n",
      "40 0.8123\n",
      "1182.451072692871\n",
      "41 0.8148\n",
      "1211.3900787830353\n",
      "42 0.8162\n",
      "1240.3415908813477\n",
      "43 0.8169\n",
      "1269.189109325409\n",
      "44 0.8165\n",
      "1298.050113916397\n",
      "45 0.8155\n",
      "1327.430114030838\n",
      "46 0.8213\n",
      "1356.4331140518188\n",
      "47 0.8209\n",
      "1385.4101226329803\n",
      "48 0.8231\n",
      "1414.4316277503967\n",
      "49 0.8232\n",
      "1443.4729325771332\n",
      "50 0.8284\n",
      "1472.53542304039\n",
      "51 0.8215\n",
      "1501.678599357605\n",
      "52 0.8264\n",
      "1530.679599761963\n",
      "53 0.8258\n",
      "1559.752599477768\n",
      "54 0.8326\n",
      "1588.7326056957245\n",
      "55 0.8395\n",
      "1617.7436091899872\n",
      "56 0.838\n",
      "1646.7606055736542\n",
      "57 0.8323\n",
      "1675.8316054344177\n",
      "58 0.8371\n",
      "1704.8976118564606\n",
      "59 0.8253\n",
      "1733.925702571869\n",
      "60 0.8289\n",
      "1762.9804084300995\n",
      "61 0.8428\n",
      "1792.032352924347\n",
      "62 0.8302\n",
      "1821.0949432849884\n",
      "63 0.8395\n",
      "1850.7108221054077\n",
      "64 0.8412\n",
      "1880.5083751678467\n",
      "65 0.8382\n",
      "1910.414379119873\n",
      "66 0.8445\n",
      "1939.5423760414124\n",
      "67 0.8425\n",
      "1968.5325362682343\n",
      "68 0.8411\n",
      "1997.521460533142\n",
      "69 0.8484\n",
      "2026.4930245876312\n",
      "70 0.8457\n",
      "2055.4580252170563\n",
      "71 0.8468\n",
      "2084.433961391449\n",
      "72 0.8396\n",
      "2113.392194509506\n",
      "73 0.845\n",
      "2142.3971943855286\n",
      "74 0.8505\n",
      "2171.439205646515\n",
      "75 0.8473\n",
      "2200.504718542099\n",
      "76 0.8485\n",
      "2229.53271818161\n",
      "77 0.8563\n",
      "2258.5878977775574\n",
      "78 0.8505\n",
      "2287.604792356491\n",
      "79 0.8497\n",
      "2316.6157920360565\n",
      "80 0.8487\n",
      "2345.9205453395844\n",
      "81 0.8525\n",
      "2375.4411120414734\n",
      "82 0.8549\n",
      "2404.6599447727203\n",
      "83 0.8522\n",
      "2434.1649441719055\n",
      "84 0.8535\n",
      "2463.1975457668304\n",
      "85 0.8564\n",
      "2492.1523866653442\n",
      "86 0.854\n",
      "2521.222675561905\n",
      "87 0.8506\n",
      "2550.2198939323425\n",
      "88 0.8532\n",
      "2579.1968936920166\n",
      "89 0.8548\n",
      "2608.211530447006\n",
      "90 0.8528\n",
      "2637.257530450821\n",
      "91 0.8563\n",
      "2666.3545305728912\n",
      "92 0.8587\n",
      "2695.410530567169\n",
      "93 0.8559\n",
      "2724.4695315361023\n",
      "94 0.8519\n",
      "2753.720579624176\n",
      "95 0.8591\n",
      "2783.1876442432404\n",
      "96 0.8521\n",
      "2812.524642944336\n",
      "97 0.8574\n",
      "2841.900436401367\n",
      "98 0.8573\n",
      "2871.5174362659454\n",
      "99 0.8574\n",
      "2901.0584359169006\n",
      "100 0.8534\n",
      "2931.545414209366\n",
      "101 0.848\n",
      "2961.574453830719\n",
      "102 0.8616\n",
      "2991.071726322174\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train(\u001b[38;5;241m350\u001b[39m)\n",
      "Cell \u001b[1;32mIn[4], line 30\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(epoch)\u001b[0m\n\u001b[0;32m     28\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     29\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m---> 30\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     31\u001b[0m total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     32\u001b[0m correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m predicted\u001b[38;5;241m.\u001b[39meq(targets)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(350)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
